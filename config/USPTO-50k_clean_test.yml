accum_count:
- 4
accum_steps:
- 0
adagrad_accumulator_init: 0
adam_beta1: 0.9
adam_beta2: 0.998
apex_opt_level: O2
audio_enc_pooling: '1'
average_decay: 0
average_every: 1
batch_size: 4096
batch_type: tokens
cnn_kernel_width: 3
data: data/USPTO-50k_clean/USPTO-50k_clean
data_ids:
- null
data_weights:
- 1
dec_layers: 2
dec_rnn_size: 500
decay_method: noam
decay_steps: 10000
decoder_type: transformer
dropout:
- 0.1
dropout_steps:
- 0
early_stopping: 0
enc_layers: 2
enc_rnn_size: 500
encoder_type: transformer
epochs: 0
exp: ''
exp_host: ''
feat_merge: concat
feat_vec_exponent: 0.7
feat_vec_size: -1
generator_function: softmax
global_attention: general
global_attention_function: softmax
gpu_backend: nccl
gpu_ranks:
- 0
gpu_verbose_level: 0
gpuid: []
heads: 8
image_channel_size: 3
input_feed: 1
keep_checkpoint: 50
label_smoothing: 0.0
lambda_coverage: 0.0
layers: 4
learning_rate: 2.0
learning_rate_decay: 0.5
log_file: ''
log_file_level: '0'
loss_scale: 0
master_ip: localhost
master_port: 10000
max_generator_batches: 32
max_grad_norm: 0.0
max_relative_positions: 0
max_segments: 10
model_dtype: fp32
model_type: text
n_latent: 1
normalization: tokens
optim: adam
param_init: 0.0
param_init_glorot: 'true'
pool_factor: 8192
position_encoding: 'true'
queue_size: 400
report_every: 1000
reset_cycle_steps: 0
reset_optim: none
rnn_size: 256
rnn_type: LSTM
sample_rate: 16000
save_checkpoint_steps: 10000
save_model: experiments/USPTO-50k_clean_test
seed: -1
self_attn_type: scaled-dot
share_embeddings: 'true'
src_word_vec_size: 500
start_decay_steps: 50000
tensorboard: 'true'
tensorboard_log_dir: runs/USPTO-50k_clean_test
tgt_word_vec_size: 500
train_from: ''
train_steps: 400000
transformer_ff: 2048
truncated_decoder: 0
valid_batch_size: 32
valid_steps: 10000
warmup_steps: 8000
window_size: 0.02
word_vec_size: 256
world_size: 1
